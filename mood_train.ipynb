{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mood_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deckel28/music-mood/blob/master/mood_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5cJdAKXRE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca0fc05-8886-4510-cc4d-4d725b688780"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUGw5jLFVhVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d521858c-13a6-46b1-e6fb-e6358768786a"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import h5py\n",
        "import numpy as np\n",
        "from numpy import savetxt\n",
        "from numpy import genfromtxt\n",
        "from numpy import random\n",
        "from random import choices\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dropout, BatchNormalization\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAFCmkHdCKKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive')\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TApXXs0bzmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = genfromtxt('Datasets/encoded_train.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_train.h5','r')\n",
        "trainX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "valY = genfromtxt('Datasets/encoded_val.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_val.h5','r')\n",
        "valX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "testY = genfromtxt('Datasets/encoded_test.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_test.h5','r')\n",
        "testX = h5f['dataset'][:]\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_X3Xe6uUc6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "40bed746-d98d-4683-d76d-943807da29d7"
      },
      "source": [
        "print('trainX-', trainX.shape, '   trainY- ', trainY.shape)\n",
        "print('valX-', valX.shape, '      valY- ', valY.shape)\n",
        "print('testX-', testX.shape, '     testY- ', testY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX- (2802, 20, 9762)    trainY-  (2802, 8)\n",
            "valX- (346, 20, 9762)       valY-  (346, 8)\n",
            "testX- (312, 20, 9762)      testY-  (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UYzW8md0Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa11bb7b-6761-4eb9-86dc-1d72e27b7027"
      },
      "source": [
        "trainX0 = np.expand_dims(trainX, axis=-1)\n",
        "valX0 = np.expand_dims(valX, axis=-1)\n",
        "testX0 = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "IN_SHAPE = trainX0.shape[1:]\n",
        "print(IN_SHAPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 9762, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWxn5RHdecn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "05d217c6-9082-4b2d-8a8c-24b2860b458c"
      },
      "source": [
        "print(trainX0.shape, valX0.shape, testX0.shape)\n",
        "print(trainY.shape, valY.shape, testY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2802, 20, 9762, 1) (346, 20, 9762, 1) (312, 20, 9762, 1)\n",
            "(2802, 8) (346, 8) (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7RymuMeWZYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(features, labels, batch_size):\n",
        "    # Create empty arrays to contain batch of features and labels#\n",
        "    batch_features = np.zeros((batch_size, IN_SHAPE[0], IN_SHAPE[1], 1))\n",
        "    batch_labels = np.zeros((batch_size, 8))\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            index = random.choice(len(features), 1)\n",
        "            batch_features[i] = features[index]\n",
        "            batch_labels[i] = labels[index]\n",
        "        yield batch_features, batch_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzL1aRD-eCq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbeta(y_true, y_pred, beta=2):\n",
        "  # clip predictions\n",
        "  y_pred = backend.clip(y_pred, 0, 1)\n",
        "  # calculate elements\n",
        "  tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "  fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "  fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "  # calculate precision\n",
        "  p = tp / (tp + fp + backend.epsilon())\n",
        "  # calculate recall\n",
        "  r = tp / (tp + fn + backend.epsilon())\n",
        "  # calculate fbeta, averaged across each class\n",
        "  bb = beta ** 2\n",
        "  fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
        "  return fbeta_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwOF3gf_KocV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_yhat = np.asarray([np.ones(data_Y.shape[1]) for _ in range(data_Y.shape[0])])\n",
        "# # test_yhat = np.asarray([np.ones(data_Y[180000:].shape[1]) for _ in range(data_Y[180000:].shape[0])])\n",
        "# print(train_yhat.shape, data_Y.shape)\n",
        "# # evaluate predictions with sklearn\n",
        "# train_score = fbeta_score(data_Y, train_yhat, 2, average='samples')\n",
        "# # test_score = fbeta_score(data_Y[180000:], test_yhat, 2, average='samples')\n",
        "# # print('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# # evaluate predictions with keras\n",
        "# train_score = fbeta(backend.variable(data_Y), backend.variable(train_yhat))\n",
        "# # test_score = fbeta(backend.variable(data_Y[180000:]), backend.variable(test_yhat))\n",
        "# # print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# train_score = accuracy_score(data_Y, train_yhat)\n",
        "# print(train_score)\n",
        "# print(keras.metrics.accuracy(data_Y, train_yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnzEqFgeGfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(in_shape, out_shape):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(60, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(out_shape, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWDlXoDImow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "bfcc8d1c-b799-47c1-d608-539758af3dda"
      },
      "source": [
        "model = define_model(in_shape = IN_SHAPE, out_shape=8)\n",
        "model.summary()\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', \n",
        "               metrics=['accuracy', fbeta, keras.metrics.categorical_accuracy])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 20, 9762, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 20, 9762, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 10, 4881, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10, 4881, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 780800)            0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 60)                46848060  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 488       \n",
            "=================================================================\n",
            "Total params: 46,960,228\n",
            "Trainable params: 46,960,100\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXDkA0vpYVkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "618db2a0-f958-4f3f-87a7-3b6c292afd6e"
      },
      "source": [
        "model.fit_generator(generator(trainX0, trainY, 24),\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=120,\n",
        "                    epochs=10,\n",
        "                    validation_data=(valX0, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 200s 2s/step - loss: 1.5792 - accuracy: 0.8122 - fbeta: 0.6224 - categorical_accuracy: 0.7069 - val_loss: 0.5963 - val_accuracy: 0.8306 - val_fbeta: 0.6747 - val_categorical_accuracy: 0.7832\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.3817 - accuracy: 0.8595 - fbeta: 0.6936 - categorical_accuracy: 0.7656 - val_loss: 0.3866 - val_accuracy: 0.8569 - val_fbeta: 0.6726 - val_categorical_accuracy: 0.8555\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.2904 - accuracy: 0.8840 - fbeta: 0.7402 - categorical_accuracy: 0.8163 - val_loss: 0.3717 - val_accuracy: 0.8551 - val_fbeta: 0.6648 - val_categorical_accuracy: 0.8121\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.2646 - accuracy: 0.9013 - fbeta: 0.7778 - categorical_accuracy: 0.8309 - val_loss: 0.3552 - val_accuracy: 0.8555 - val_fbeta: 0.6319 - val_categorical_accuracy: 0.7601\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.2517 - accuracy: 0.9068 - fbeta: 0.7847 - categorical_accuracy: 0.8417 - val_loss: 0.3400 - val_accuracy: 0.8540 - val_fbeta: 0.6658 - val_categorical_accuracy: 0.8295\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.2285 - accuracy: 0.9195 - fbeta: 0.8186 - categorical_accuracy: 0.8128 - val_loss: 0.3352 - val_accuracy: 0.8627 - val_fbeta: 0.6782 - val_categorical_accuracy: 0.8266\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.2188 - accuracy: 0.9244 - fbeta: 0.8289 - categorical_accuracy: 0.8368 - val_loss: 0.3577 - val_accuracy: 0.8598 - val_fbeta: 0.6325 - val_categorical_accuracy: 0.8150\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 193s 2s/step - loss: 0.2124 - accuracy: 0.9290 - fbeta: 0.8457 - categorical_accuracy: 0.8188 - val_loss: 0.3398 - val_accuracy: 0.8616 - val_fbeta: 0.6792 - val_categorical_accuracy: 0.8179\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 192s 2s/step - loss: 0.1998 - accuracy: 0.9339 - fbeta: 0.8587 - categorical_accuracy: 0.8417 - val_loss: 0.3745 - val_accuracy: 0.8634 - val_fbeta: 0.6691 - val_categorical_accuracy: 0.8208\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 193s 2s/step - loss: 0.2162 - accuracy: 0.9296 - fbeta: 0.8463 - categorical_accuracy: 0.8333 - val_loss: 0.3737 - val_accuracy: 0.8613 - val_fbeta: 0.6545 - val_categorical_accuracy: 0.8642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa380178e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Ro_4_nCcjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5e2b6d1a-89c3-4b95-ca25-c9cafab40c63"
      },
      "source": [
        "model.save('Models/model1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "  'TensorFlow optimizers do not '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF5cWAExEcya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresholds = [['Happy', 0.8],\n",
        "                ['Excited', 0.5],\n",
        "                ['Frantic', 0.5],\n",
        "                ['Anxious/Sad', 0.3],\n",
        "                ['Anger', 0.5],\n",
        "                ['Calm', 0.22],\n",
        "                ['Tired', 0.5],\n",
        "                ['Sensual', 0.1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3JFv0LdENg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8db45c31-991f-4e4e-c7bd-1e30be99fb32"
      },
      "source": [
        "predictions = model.predict(trainX0)\n",
        "y_pred=np.zeros((trainX0.shape[0],8))\n",
        "for i in range(trainX0[:5000].shape[0]):\n",
        "    for j in range(8):\n",
        "        y_pred[i][j] = (predictions[i][j]>thresholds[j][1])\n",
        "print(y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2802, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW1aXwYN_bN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ed449b8e-44eb-42c6-8712-a75c27c15359"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "\n",
        "accuracy = accuracy_score(trainY, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "f1 = fbeta(trainY, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "hl = hamming_loss(trainY, y_pred)\n",
        "print('Hamming Loss: %f' % hl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.178087\n",
            "F1 score: 0.798583\n",
            "Hamming Loss: 0.134234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29An7UP5KnP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}