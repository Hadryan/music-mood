{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mood_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deckel28/music-mood/blob/master/mood_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5cJdAKXRE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bdd61ba-7627-42a8-dec7-a52c19753e9d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUGw5jLFVhVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9f0aa17-4e94-4857-fb0d-90a5f9ed27ee"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import h5py\n",
        "import numpy as np\n",
        "from numpy import savetxt\n",
        "from numpy import genfromtxt\n",
        "from numpy import random\n",
        "from random import choices\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dropout, BatchNormalization\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAFCmkHdCKKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "7c97fa37-f539-401e-9a61-5ce88378d128"
      },
      "source": [
        "os.chdir('/content/drive/My Drive')\n",
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mood_pred.ipynb',\n",
              " 'mood_train.ipynb',\n",
              " 'feats_test.h5',\n",
              " 'encoded_test.csv',\n",
              " 'GoogleNews-vectors-negative300.bin',\n",
              " 'feats_train.h5',\n",
              " 'encoded_train.csv',\n",
              " 'feats_val.h5',\n",
              " 'encoded_val.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TApXXs0bzmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = genfromtxt('encoded_train.csv', delimiter=',')\n",
        "h5f = h5py.File('./feats_train.h5','r')\n",
        "trainX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "valY = genfromtxt('encoded_val.csv', delimiter=',')\n",
        "h5f = h5py.File('./feats_val.h5','r')\n",
        "valX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "testY = genfromtxt('encoded_test.csv', delimiter=',')\n",
        "h5f = h5py.File('./feats_test.h5','r')\n",
        "testX = h5f['dataset'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_X3Xe6uUc6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fdffab03-0606-4045-862c-dd954331c00a"
      },
      "source": [
        "print('trainX-', trainX.shape, '   trainY- ', trainY.shape)\n",
        "print('valX-', valX.shape, '      valY- ', valY.shape)\n",
        "print('testX-', testX.shape, '     testY- ', testY.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX- (2802, 20, 9762)    trainY-  (2802, 8)\n",
            "valX- (346, 20, 9762)       valY-  (346, 8)\n",
            "testX- (312, 20, 9762)      testY-  (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UYzW8md0Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28298a0b-fbd2-4b2b-83e5-61c5cb31685c"
      },
      "source": [
        "trainX0 = np.expand_dims(trainX, axis=-1)\n",
        "valX0 = np.expand_dims(valX, axis=-1)\n",
        "testX0 = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "IN_SHAPE = trainX0.shape[1:]\n",
        "print(IN_SHAPE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 9762, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWxn5RHdecn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5ed70786-e608-4ece-e71a-dac9120a543c"
      },
      "source": [
        "print(trainX0.shape, valX0.shape, testX0.shape)\n",
        "print(trainY.shape, valY.shape, testY.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2802, 20, 9762, 1) (346, 20, 9762, 1) (312, 20, 9762, 1)\n",
            "(2802, 8) (346, 8) (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7RymuMeWZYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(features, labels, batch_size):\n",
        "    # Create empty arrays to contain batch of features and labels#\n",
        "    batch_features = np.zeros((batch_size, IN_SHAPE[0], IN_SHAPE[1], 1))\n",
        "    batch_labels = np.zeros((batch_size, 8))\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            index = random.choice(len(features), 1)\n",
        "            batch_features[i] = features[index]\n",
        "            batch_labels[i] = labels[index]\n",
        "        yield batch_features, batch_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzL1aRD-eCq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbeta(y_true, y_pred, beta=2):\n",
        "  # clip predictions\n",
        "  y_pred = backend.clip(y_pred, 0, 1)\n",
        "  # calculate elements\n",
        "  tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "  fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "  fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "  # calculate precision\n",
        "  p = tp / (tp + fp + backend.epsilon())\n",
        "  # calculate recall\n",
        "  r = tp / (tp + fn + backend.epsilon())\n",
        "  # calculate fbeta, averaged across each class\n",
        "  bb = beta ** 2\n",
        "  fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
        "  return fbeta_score"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwOF3gf_KocV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_yhat = np.asarray([np.ones(data_Y.shape[1]) for _ in range(data_Y.shape[0])])\n",
        "# # test_yhat = np.asarray([np.ones(data_Y[180000:].shape[1]) for _ in range(data_Y[180000:].shape[0])])\n",
        "# print(train_yhat.shape, data_Y.shape)\n",
        "# # evaluate predictions with sklearn\n",
        "# train_score = fbeta_score(data_Y, train_yhat, 2, average='samples')\n",
        "# # test_score = fbeta_score(data_Y[180000:], test_yhat, 2, average='samples')\n",
        "# # print('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# # evaluate predictions with keras\n",
        "# train_score = fbeta(backend.variable(data_Y), backend.variable(train_yhat))\n",
        "# # test_score = fbeta(backend.variable(data_Y[180000:]), backend.variable(test_yhat))\n",
        "# # print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# train_score = accuracy_score(data_Y, train_yhat)\n",
        "# print(train_score)\n",
        "# print(keras.metrics.accuracy(data_Y, train_yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnzEqFgeGfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(in_shape, out_shape):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "#   model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "#   model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(60, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(out_shape, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_BWT2dWiEYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn import metrics\n",
        "# from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "\n",
        "# def f1micro(y_true, y_pred):\n",
        "#     return tf.py_func(f1_score(y_true, y_pred,average='mirco'),tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bmw67Ncl91B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def accuracy_score(ytrue, ypred):\n",
        "#     y_pred=np.zeros((ytrue.shape[0],8))\n",
        "#     for i in range(ytrue.shape[0]):\n",
        "#         for j in range(8):\n",
        "#             y_pred[i][j] = (ypred[i][j]>thresholds[j][1])\n",
        "    \n",
        "\n",
        "# def AUC(y_true,y_pred):\n",
        "#     not_y_pred=np.logical_not(y_pred)\n",
        "#     y_int1=y_true*y_pred\n",
        "#     y_int0=np.logical_not(y_true)*not_y_pred\n",
        "#     TP=np.sum(y_pred*y_int1)\n",
        "#     FP=np.sum(y_pred)-TP\n",
        "#     TN=np.sum(not_y_pred*y_int0)\n",
        "#     FN=np.sum(not_y_pred)-TN\n",
        "#     TPR=np.float(TP)/(TP+FN)\n",
        "#     FPR=np.float(FP)/(FP+TN)\n",
        "#     return (1+TPR-FPR)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWDlXoDImow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "83f60c91-e413-459b-fae5-89e5484f9428"
      },
      "source": [
        "model = define_model(in_shape = IN_SHAPE, out_shape=8)\n",
        "model.summary()\n",
        "opt = keras.optimizers.Adam(lr=0.00001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', \n",
        "               metrics=['accuracy', fbeta, keras.metrics.categorical_accuracy])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 20, 9762, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 20, 9762, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 10, 4881, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 4881, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 780800)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 60)                46848060  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 488       \n",
            "=================================================================\n",
            "Total params: 46,960,228\n",
            "Trainable params: 46,960,100\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXDkA0vpYVkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "819207d0-fcbd-41b5-b65e-ba156d14a8bd"
      },
      "source": [
        "model.fit_generator(generator(trainX0, trainY, 40),\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=80,\n",
        "                    epochs=20,\n",
        "                    validation_data=(valX0, valY))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2960 - accuracy: 0.8739 - fbeta: 0.7030 - categorical_accuracy: 0.8369 - val_loss: 0.3389 - val_accuracy: 0.8504 - val_fbeta: 0.6771 - val_categorical_accuracy: 0.8237\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2725 - accuracy: 0.8927 - fbeta: 0.7461 - categorical_accuracy: 0.8537 - val_loss: 0.3381 - val_accuracy: 0.8522 - val_fbeta: 0.6809 - val_categorical_accuracy: 0.8208\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2642 - accuracy: 0.8946 - fbeta: 0.7458 - categorical_accuracy: 0.8578 - val_loss: 0.3414 - val_accuracy: 0.8530 - val_fbeta: 0.6732 - val_categorical_accuracy: 0.8295\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2773 - accuracy: 0.8889 - fbeta: 0.7412 - categorical_accuracy: 0.8416 - val_loss: 0.3477 - val_accuracy: 0.8544 - val_fbeta: 0.6505 - val_categorical_accuracy: 0.8150\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2595 - accuracy: 0.9001 - fbeta: 0.7691 - categorical_accuracy: 0.8450 - val_loss: 0.3356 - val_accuracy: 0.8671 - val_fbeta: 0.6856 - val_categorical_accuracy: 0.8382\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2580 - accuracy: 0.8985 - fbeta: 0.7649 - categorical_accuracy: 0.8450 - val_loss: 0.3449 - val_accuracy: 0.8580 - val_fbeta: 0.6354 - val_categorical_accuracy: 0.8555\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2474 - accuracy: 0.9063 - fbeta: 0.7841 - categorical_accuracy: 0.8603 - val_loss: 0.3431 - val_accuracy: 0.8559 - val_fbeta: 0.6512 - val_categorical_accuracy: 0.8642\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2521 - accuracy: 0.9061 - fbeta: 0.7914 - categorical_accuracy: 0.8544 - val_loss: 0.3476 - val_accuracy: 0.8530 - val_fbeta: 0.6626 - val_categorical_accuracy: 0.7832\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2467 - accuracy: 0.9084 - fbeta: 0.7929 - categorical_accuracy: 0.8550 - val_loss: 0.3411 - val_accuracy: 0.8548 - val_fbeta: 0.6685 - val_categorical_accuracy: 0.8237\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2398 - accuracy: 0.9126 - fbeta: 0.8041 - categorical_accuracy: 0.8562 - val_loss: 0.3388 - val_accuracy: 0.8613 - val_fbeta: 0.6497 - val_categorical_accuracy: 0.8642\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2488 - accuracy: 0.9068 - fbeta: 0.7916 - categorical_accuracy: 0.8481 - val_loss: 0.3492 - val_accuracy: 0.8580 - val_fbeta: 0.6704 - val_categorical_accuracy: 0.8497\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2522 - accuracy: 0.9086 - fbeta: 0.7977 - categorical_accuracy: 0.8416 - val_loss: 0.3389 - val_accuracy: 0.8569 - val_fbeta: 0.6658 - val_categorical_accuracy: 0.8208\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2430 - accuracy: 0.9120 - fbeta: 0.8048 - categorical_accuracy: 0.8416 - val_loss: 0.3407 - val_accuracy: 0.8638 - val_fbeta: 0.6386 - val_categorical_accuracy: 0.8353\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2664 - accuracy: 0.9021 - fbeta: 0.7873 - categorical_accuracy: 0.8459 - val_loss: 0.3392 - val_accuracy: 0.8602 - val_fbeta: 0.6229 - val_categorical_accuracy: 0.8497\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2501 - accuracy: 0.9109 - fbeta: 0.8083 - categorical_accuracy: 0.8447 - val_loss: 0.3409 - val_accuracy: 0.8591 - val_fbeta: 0.6512 - val_categorical_accuracy: 0.8382\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2616 - accuracy: 0.9045 - fbeta: 0.7925 - categorical_accuracy: 0.8447 - val_loss: 0.3587 - val_accuracy: 0.8468 - val_fbeta: 0.6920 - val_categorical_accuracy: 0.8295\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2443 - accuracy: 0.9119 - fbeta: 0.8058 - categorical_accuracy: 0.8547 - val_loss: 0.3534 - val_accuracy: 0.8580 - val_fbeta: 0.6170 - val_categorical_accuracy: 0.8613\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2543 - accuracy: 0.9079 - fbeta: 0.8001 - categorical_accuracy: 0.8444 - val_loss: 0.3487 - val_accuracy: 0.8634 - val_fbeta: 0.6626 - val_categorical_accuracy: 0.8584\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2380 - accuracy: 0.9168 - fbeta: 0.8178 - categorical_accuracy: 0.8459 - val_loss: 0.3654 - val_accuracy: 0.8428 - val_fbeta: 0.6892 - val_categorical_accuracy: 0.8439\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 110s 1s/step - loss: 0.2344 - accuracy: 0.9195 - fbeta: 0.8264 - categorical_accuracy: 0.8369 - val_loss: 0.3997 - val_accuracy: 0.8428 - val_fbeta: 0.5823 - val_categorical_accuracy: 0.8584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f794df50898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Ro_4_nCcjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "39705b32-55f3-4a55-e3bf-8b56e3344718"
      },
      "source": [
        "model1.save('model.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "  'TensorFlow optimizers do not '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF5cWAExEcya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresholds = [['Happy', 0.8],\n",
        "                ['Excited', 0.5],\n",
        "                ['Frantic', 0.5],\n",
        "                ['Anxious/Sad', 0.3],\n",
        "                ['Anger', 0.5],\n",
        "                ['Calm', 0.22],\n",
        "                ['Tired', 0.5],\n",
        "                ['Sensual', 0.1]]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3JFv0LdENg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8db45c31-991f-4e4e-c7bd-1e30be99fb32"
      },
      "source": [
        "predictions = model.predict(trainX0)\n",
        "y_pred=np.zeros((trainX0.shape[0],8))\n",
        "for i in range(trainX0[:5000].shape[0]):\n",
        "    for j in range(8):\n",
        "        y_pred[i][j] = (predictions[i][j]>thresholds[j][1])\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2802, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW1aXwYN_bN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ed449b8e-44eb-42c6-8712-a75c27c15359"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "\n",
        "accuracy = accuracy_score(trainY, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "f1 = fbeta(trainY, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "hl = hamming_loss(trainY, y_pred)\n",
        "print('Hamming Loss: %f' % hl)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.178087\n",
            "F1 score: 0.798583\n",
            "Hamming Loss: 0.134234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29An7UP5KnP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}