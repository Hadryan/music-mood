{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mood_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deckel28/music-mood/blob/master/mood_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5cJdAKXRE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "174a4cb9-0dbc-4a86-ee6e-97d4ef95ad39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUGw5jLFVhVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a414a12-9af0-4b7e-87e0-287a913c82ab"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import h5py\n",
        "import numpy as np\n",
        "from numpy import savetxt\n",
        "from numpy import genfromtxt\n",
        "from numpy import random\n",
        "from random import choices\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dropout, BatchNormalization\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAFCmkHdCKKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive')\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TApXXs0bzmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = genfromtxt('Datasets/encoded_train.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_train.h5','r')\n",
        "trainX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "valY = genfromtxt('Datasets/encoded_val.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_val.h5','r')\n",
        "valX = h5f['dataset'][:]\n",
        "h5f.close()\n",
        "\n",
        "testY = genfromtxt('Datasets/encoded_test.csv', delimiter=',')\n",
        "h5f = h5py.File('Datasets/feats_test.h5','r')\n",
        "testX = h5f['dataset'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_X3Xe6uUc6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "32d7a780-e549-4d37-a1cd-9dd346af8b9d"
      },
      "source": [
        "print('trainX-', trainX.shape, '   trainY- ', trainY.shape)\n",
        "print('valX-', valX.shape, '      valY- ', valY.shape)\n",
        "print('testX-', testX.shape, '     testY- ', testY.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX- (2802, 20, 9762)    trainY-  (2802, 8)\n",
            "valX- (346, 20, 9762)       valY-  (346, 8)\n",
            "testX- (312, 20, 9762)      testY-  (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr0Y4mb6K1_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f617323-5a02-4e06-ff2f-c24b77688c57"
      },
      "source": [
        "totalY = np.concatenate((trainY, valY, testY))\n",
        "print(np.sum(totalY, axis=0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3009. 1528.    9. 1052.  171.  796.   27.  419.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UYzW8md0Ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a93b8db0-659f-40f5-f5e4-7d8da5e6ae0b"
      },
      "source": [
        "trainX0 = np.expand_dims(trainX, axis=-1)\n",
        "valX0 = np.expand_dims(valX, axis=-1)\n",
        "testX0 = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "IN_SHAPE = trainX0.shape[1:]\n",
        "print(IN_SHAPE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 9762, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWxn5RHdecn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "80a5a00b-e571-4700-c9cf-764d4ea24e26"
      },
      "source": [
        "print(trainX0.shape, valX0.shape, testX0.shape)\n",
        "print(trainY.shape, valY.shape, testY.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2802, 20, 9762, 1) (346, 20, 9762, 1) (312, 20, 9762, 1)\n",
            "(2802, 8) (346, 8) (312, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7RymuMeWZYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(features, labels, batch_size):\n",
        "    # Create empty arrays to contain batch of features and labels#\n",
        "    batch_features = np.zeros((batch_size, IN_SHAPE[0], IN_SHAPE[1], 1))\n",
        "    batch_labels = np.zeros((batch_size, 8))\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            index = random.choice(len(features), 1)\n",
        "            batch_features[i] = features[index]\n",
        "            batch_labels[i] = labels[index]\n",
        "        yield batch_features, batch_labels"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzL1aRD-eCq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fbeta(y_true, y_pred, beta=2):\n",
        "  # clip predictions\n",
        "  y_pred = backend.clip(y_pred, 0, 1)\n",
        "  # calculate elements\n",
        "  tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "  fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "  fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "  # calculate precision\n",
        "  p = tp / (tp + fp + backend.epsilon())\n",
        "  # calculate recall\n",
        "  r = tp / (tp + fn + backend.epsilon())\n",
        "  # calculate fbeta, averaged across each class\n",
        "  bb = beta ** 2\n",
        "  fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
        "  return fbeta_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnzEqFgeGfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(in_shape, out_shape):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(60, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(out_shape, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWDlXoDImow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "3a0a0760-bb76-4dd3-9578-d23e5021b5df"
      },
      "source": [
        "model = define_model(in_shape = IN_SHAPE, out_shape=8)\n",
        "model.summary()\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', \n",
        "               metrics=['accuracy', fbeta, keras.metrics.categorical_accuracy])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 20, 9762, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 9762, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 10, 4881, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10, 4881, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 4881, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 2440, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 780800)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 60)                46848060  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 488       \n",
            "=================================================================\n",
            "Total params: 46,960,228\n",
            "Trainable params: 46,960,100\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXDkA0vpYVkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "92211937-3296-46f3-b187-a5eb058bd91d"
      },
      "source": [
        "model.fit_generator(generator(trainX0, trainY, 24),\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=120,\n",
        "                    epochs=5,\n",
        "                    validation_data=(valX0, valY))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "120/120 [==============================] - 198s 2s/step - loss: 1.7730 - accuracy: 0.8124 - fbeta: 0.6258 - categorical_accuracy: 0.7010 - val_loss: 0.7492 - val_accuracy: 0.8555 - val_fbeta: 0.6344 - val_categorical_accuracy: 0.8584\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 186s 2s/step - loss: 0.4032 - accuracy: 0.8587 - fbeta: 0.6882 - categorical_accuracy: 0.7819 - val_loss: 0.4047 - val_accuracy: 0.8461 - val_fbeta: 0.6590 - val_categorical_accuracy: 0.7977\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 186s 2s/step - loss: 0.3126 - accuracy: 0.8841 - fbeta: 0.7343 - categorical_accuracy: 0.8059 - val_loss: 0.4445 - val_accuracy: 0.7988 - val_fbeta: 0.6577 - val_categorical_accuracy: 0.2948\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 186s 2s/step - loss: 0.2610 - accuracy: 0.8986 - fbeta: 0.7761 - categorical_accuracy: 0.8271 - val_loss: 0.3688 - val_accuracy: 0.8555 - val_fbeta: 0.6558 - val_categorical_accuracy: 0.8642\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 186s 2s/step - loss: 0.2242 - accuracy: 0.9201 - fbeta: 0.8207 - categorical_accuracy: 0.8562 - val_loss: 0.3505 - val_accuracy: 0.8624 - val_fbeta: 0.6518 - val_categorical_accuracy: 0.8526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa307d52278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Ro_4_nCcjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Models/modelxxx.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwOF3gf_KocV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_yhat = np.asarray([np.ones(data_Y.shape[1]) for _ in range(data_Y.shape[0])])\n",
        "# # test_yhat = np.asarray([np.ones(data_Y[180000:].shape[1]) for _ in range(data_Y[180000:].shape[0])])\n",
        "# print(train_yhat.shape, data_Y.shape)\n",
        "# # evaluate predictions with sklearn\n",
        "# train_score = fbeta_score(data_Y, train_yhat, 2, average='samples')\n",
        "# # test_score = fbeta_score(data_Y[180000:], test_yhat, 2, average='samples')\n",
        "# # print('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# # evaluate predictions with keras\n",
        "# train_score = fbeta(backend.variable(data_Y), backend.variable(train_yhat))\n",
        "# # test_score = fbeta(backend.variable(data_Y[180000:]), backend.variable(test_yhat))\n",
        "# # print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# print(train_score)\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# train_score = accuracy_score(data_Y, train_yhat)\n",
        "# print(train_score)\n",
        "# print(keras.metrics.accuracy(data_Y, train_yhat))"
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}